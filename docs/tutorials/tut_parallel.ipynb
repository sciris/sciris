{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization and profiling\n",
    "\n",
    "If you're one of those people whose scripts always run in a second or less, you can probably skip this tutorial. But if you have time to make yourself a cup of tea while your code is running, you might want to read on. This tutorial covers how to run code in parallel, and how to check its performance to look for improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Click [here](https://mybinder.org/v2/gh/sciris/sciris/HEAD?labpath=docs%2Ftutorials%2Ftut_parallel.ipynb) to open an interactive version of this notebook.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parallelization\n",
    "\n",
    "\n",
    "### Parallelization in Python\n",
    "\n",
    "Scary stories of Python's [\"global interpreter lock\"](https://granulate.io/blog/introduction-to-the-infamous-python-gil/) aside, parallelization is actually fairly simple in Python. However, it's not particularly intuitive or flexible. We can do vanilla parallelization in Python via something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Define a function\n",
    "def my_func(x):\n",
    "    return x**2\n",
    "\n",
    "# Run it in parallel\n",
    "with mp.Pool() as pool:\n",
    "    results = pool.map(my_func, [1,2,3])\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. But what if we have something more complicated? What if we want to run our function with a different keyword argument, for example? It starts getting kind of crazy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Define a (slightly) more complex function\n",
    "def complex_func(x, arg1=2, arg2=4):\n",
    "    return x**2 + (arg1 * arg2)\n",
    "\n",
    "# Make a new function with a different default argument ðŸ˜±\n",
    "new_func = partial(complex_func, arg2=10)\n",
    "\n",
    "# Run it in parallel\n",
    "with mp.Pool() as pool:\n",
    "    results = pool.map(new_func, [1,2,3])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but that sure was a lot of work just to set a single keyword argument! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization in Sciris\n",
    "\n",
    "With Sciris, you can do it all with one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciris as sc\n",
    "\n",
    "results = sc.parallelize(complex_func, [1,2,3], arg2=10)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here? `sc.parallelize()` lets you pass keyword arguments directly to the function you're calling. You can also iterate over multiple arguments rather than just one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(x=[1,2,3], arg2=[10,20,30])\n",
    "\n",
    "results = sc.parallelize(complex_func, iterkwargs=args)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Of course you can do this with vanilla Python too, but you'll need to define a list of tuples, and you can only assign by position, not by keyword.)\n",
    "\n",
    "Depending on what you might want to run, your inputs might be in one of several different forms. You can supply a list of values, a list of dicts, or a dict of lists. An example will probably help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(x,y):\n",
    "    return x*y\n",
    "\n",
    "r1 = sc.parallelize(mult, iterarg=[(1,2),(2,3),(3,4)])\n",
    "r2 = sc.parallelize(mult, iterkwargs={'x':[1,2,3], 'y':[2,3,4]})\n",
    "r3 = sc.parallelize(mult, iterkwargs=[{'x':1, 'y':2}, {'x':2, 'y':3}, {'x':3, 'y':4}])\n",
    "print(f'{r1 = }')\n",
    "print(f'{r2 = }')\n",
    "print(f'{r3 = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these are equivalent: choose whichever makes you happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced usage\n",
    "\n",
    "There are lots and lots of options with parallelization, but we'll only cover a couple here. For example, if you want to start 200 jobs on your laptop with 8 cores, you probably don't want them to eat up all your CPU or memory and make your computer unusable. You can set `maxcpu` and `maxmem` limits to handle that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the function\n",
    "def rand2d(i, x, y):\n",
    "    np.random.seed()\n",
    "    xy = [x+i*np.random.randn(100), y+i*np.random.randn(100)]\n",
    "    return (i,xy)\n",
    "\n",
    "# Run in parallel\n",
    "xy = sc.parallelize(\n",
    "    func     = rand2d,   # The function to parallelize\n",
    "    iterarg  = range(5), # Values for first argument\n",
    "    maxcpu   = 0.8,      # CPU limit (1 = no limit)\n",
    "    maxmem   = 0.9,      # Memory limit (1 = no limit)\n",
    "    interval = 0.2,      # How often to re-check the limits (in seconds)\n",
    "    x = 3, y = 8,        # Keyword arguments for the function\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "colors = sc.gridcolors(len(xy))\n",
    "for i,(x,y) in reversed(xy): # Reverse order to plot the most widely spaced dots first\n",
    "    plt.scatter(x, y, c=[colors[i]], alpha=0.7, label=f'Scale={i}')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've used `sc.parallelize()` as a function. But you can also use it as a class, which gives you more flexibility and control over which jobs are run, and will give you more information if any of them failed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_func(i=1):\n",
    "    sc.randsleep(seed=i)\n",
    "    if i == 4:\n",
    "        raise Exception(\"I don't like seed 4\")\n",
    "    return i**2\n",
    "\n",
    "# Create the parallelizer object\n",
    "P = sc.Parallel(\n",
    "    func = slow_func,\n",
    "    iterarg = range(10),\n",
    "    parallelizer = 'multiprocess-async', # Run asynchronously\n",
    "    die = False, # Keep going if a job crashes\n",
    ")\n",
    "\n",
    "# Actually run\n",
    "P.run_async()\n",
    "\n",
    "# Monitor progress\n",
    "P.monitor()\n",
    "\n",
    "# Get results\n",
    "P.finalize()\n",
    "\n",
    "# See how long things took\n",
    "print(P.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see it raised some warnings. These are stored in the `Parallel` object so we can check back and see what happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{P.success = }')\n",
    "print(f'{P.exceptions = }')\n",
    "print(f'{P.results = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you will never need to run a function as poorly written as `slow_func()`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "\n",
    "Even parallelization can't save you if your code is just really slow. Sciris provides a variety of tools to help with this.\n",
    "\n",
    "### Benchmarking\n",
    "\n",
    "First off, we can check if our computer is performing as we expect, or if we want to compare across computers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = sc.benchmark() # Check CPU performance, in units of MOPS (million operations per second)\n",
    "ml = sc.memload() # Check total memory load\n",
    "ram = sc.checkram() # Check RAM used by this Python instance\n",
    "\n",
    "print('CPU performance: ', dict(bm))\n",
    "print('System memory load', ml)\n",
    "print('Python RAM usage', ram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that NumPy performance is much higher than Python â€“ hundreds of MOPSâ€  instead of single-digits. This makes sense, this is why we use it for array operations!\n",
    "\n",
    "*â€  The determination of a single \"operation\" is a little loose, so these \"MOPS\" can be used for relative purposes, but aren't directly relatable to, say, published processor speeds.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line profiling\n",
    "\n",
    "If you want to do a serious profiling of your code, take a look at [Austin](https://github.com/P403n1x87/austin). But if you just want to get a quick sense of where things might be slow, you can use `sc.profile()`. Applying it to our lousy `slow_func()` from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.profile(slow_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 100% (well, 99.9997%) of the time was taken by the sleep function. This is not surprising, but seems correct!\n",
    "\n",
    "For a slightly more realistic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    n = 1000\n",
    "    \n",
    "    # Do some NumPy\n",
    "    v1 = np.random.rand(n,n)\n",
    "    v2 = np.random.rand(n,n)\n",
    "    v3 = v1*v2\n",
    "    \n",
    "    # Do some Python\n",
    "    means = []\n",
    "    for i in range(n):\n",
    "        means.append(sum(v3[i])/n)\n",
    "\n",
    "sc.profile(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see (from the \"`% Time`\" column) that, again not surprisingly, the Python math operation is much slower than the NumPy operations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
